{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c6251-6b0a-4639-a995-036a28c073f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "# !pip install sentence-transformers\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbbce647-f1d8-4d34-ad49-2eb8239987a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gke/py312env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import warnings\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import difflib\n",
    "import tqdm\n",
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "import itertools\n",
    "import torch\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO\n",
    ")\n",
    "from torch.utils.data import DataLoader , IterableDataset , Dataset\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import BertTokenizer, BertLMHeadModel, AutoConfig\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "283663a7-5299-4b02-8cc4-a67752f66256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_a_answer</th>\n",
       "      <th>model_b_answer</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I don't have personal beliefs or opi...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53567</td>\n",
       "      <td>How can I get both of them as quick as possibl...</td>\n",
       "      <td>If you want to get both a marriage license and...</td>\n",
       "      <td>In California, here are the general steps to o...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                             prompt  \\\n",
       "0  30192  Is it morally right to try to have a certain p...   \n",
       "1  53567  What is the difference between marriage licens...   \n",
       "2  53567  How can I get both of them as quick as possibl...   \n",
       "\n",
       "                                      model_a_answer  \\\n",
       "0  The question of whether it is morally right to...   \n",
       "1  A marriage license is a legal document that al...   \n",
       "2  If you want to get both a marriage license and...   \n",
       "\n",
       "                                      model_b_answer winner  \n",
       "0  As an AI, I don't have personal beliefs or opi...      A  \n",
       "1  A marriage license and a marriage certificate ...      B  \n",
       "2  In California, here are the general steps to o...      B  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config = AutoConfig\n",
    "model = BertLMHeadModel.from_pretrained(\"google-bert/bert-large-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-large-uncased\")\n",
    "\n",
    "dfn = pd.read_csv(\"lmsys-chatbot-arena/aux_files/dfn.csv\")\n",
    "unique_ids = dfn.id.unique()\n",
    "dfn.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc764ef-039b-4ed8-98e5-88feece37417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 56759/56759 [00:06<00:00, 8965.02it/s]\n"
     ]
    }
   ],
   "source": [
    "id_list = []\n",
    "id_strings = []\n",
    "\n",
    "for _id in tqdm.tqdm(unique_ids):\n",
    "    id_df = dfn[dfn.id == _id]\n",
    "    id_str = \"\"\n",
    "    \n",
    "    for row in id_df.iterrows():\n",
    "        prompt = str(row[1]['prompt'])\n",
    "        \n",
    "        model_a_answer = str(row[1]['model_a_answer'])\n",
    "        model_b_answer = str(row[1]['model_b_answer'])\n",
    "        winner = row[1]['winner']\n",
    "\n",
    "        if winner == \"A\":\n",
    "            id_str += prompt + \"\\n\" + model_a_answer +'\\n'\n",
    "        if winner == \"B\":\n",
    "            id_str += prompt + \"\\n\" + model_b_answer +'\\n'\n",
    "    \n",
    "    if len(id_str) > 10:\n",
    "        id_strings.append(str(id_str))\n",
    "        id_list.append(str(_id))\n",
    "\n",
    "cut = int(len(id_strings) * 0.2)\n",
    "\n",
    "id_strings_train = id_strings[0:len(id_strings) - cut]\n",
    "id_strings_test = id_strings[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab00327-2132-4b8a-a003-c558c4bda721",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocsDataset(Dataset):\n",
    "    def tokenize_ans(self , examples):\n",
    "        return tokenizer(examples, padding='max_length' , max_length=512 , truncation=True , return_tensors='pt')\n",
    "    \n",
    "    def __init__(self, str_list):\n",
    "        self.str_list = str_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.str_list)\n",
    "        \n",
    "    def __getitem__(self , idx):\n",
    "        tokenized_str_map = self.tokenize_ans(self.str_list[idx])\n",
    "        tokenized_str_map['labels'] = tokenized_str_map['input_ids']\n",
    "        return tokenized_str_map\n",
    "\n",
    "dataset_docs_train = DocsDataset(id_strings_train)\n",
    "dataset_docs_train_dataloader = DataLoader(dataset_docs_train, batch_size=4)\n",
    "\n",
    "dataset_docs_test = DocsDataset(id_strings_test)\n",
    "dataset_docs_test_dataloader = DataLoader(dataset_docs_test, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15a0d69b-85ce-4bc3-80f7-d7d0ccf76901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                     | 0/6 [06:47<?, ?it/s]\u001b[A\n",
      "\n",
      " 17%|███████▌                                     | 1/6 [00:45<03:48, 45.61s/it]\u001b[A\n",
      " 33%|███████████████                              | 2/6 [01:28<02:55, 43.92s/it]\u001b[A\n",
      " 50%|██████████████████████▌                      | 3/6 [02:13<02:13, 44.43s/it]\u001b[A\n",
      " 67%|██████████████████████████████               | 4/6 [02:53<01:25, 42.82s/it]\u001b[A\n",
      " 83%|█████████████████████████████████████▌       | 5/6 [03:32<00:41, 41.22s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 6/6 [04:13<00:00, 41.29s/it]\u001b[A\n",
      "7it [04:57, 42.01s/it]                                                          \u001b[A\n",
      "8it [05:35, 40.78s/it]\u001b[A\n",
      "9it [06:11, 39.52s/it]\u001b[A\n",
      "10it [06:51, 39.41s/it]\u001b[A\n",
      "11it [07:28, 38.74s/it]\u001b[A\n",
      "12it [08:07, 38.85s/it]\u001b[A\n",
      "13it [08:47, 39.22s/it]\u001b[A\n",
      "14it [09:26, 39.07s/it]\u001b[A\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "import tqdm\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "# num_training_steps = num_epochs * len(dataset_docs_train_dataloader)\n",
    "num_training_steps = num_epochs * 2\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataset_docs_train_dataloader:\n",
    "        batch = {k: torch.squeeze(v , 1) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba57511-ee81-4952-a3f7-509d2f8eb1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
