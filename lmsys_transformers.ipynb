{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495c6251-6b0a-4639-a995-036a28c073f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "# !pip install sentence-transformers\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbbce647-f1d8-4d34-ad49-2eb8239987a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import warnings\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import difflib\n",
    "import tqdm\n",
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "import itertools\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO\n",
    ")\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "283663a7-5299-4b02-8cc4-a67752f66256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-large-uncased\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google-bert/bert-large-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392668af-2a53-48bf-9bea-f2e9f9d46c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_a_answer</th>\n",
       "      <th>model_b_answer</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I don't have personal beliefs or opi...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53567</td>\n",
       "      <td>How can I get both of them as quick as possibl...</td>\n",
       "      <td>If you want to get both a marriage license and...</td>\n",
       "      <td>In California, here are the general steps to o...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                             prompt  \\\n",
       "0  30192  Is it morally right to try to have a certain p...   \n",
       "1  53567  What is the difference between marriage licens...   \n",
       "2  53567  How can I get both of them as quick as possibl...   \n",
       "\n",
       "                                      model_a_answer  \\\n",
       "0  The question of whether it is morally right to...   \n",
       "1  A marriage license is a legal document that al...   \n",
       "2  If you want to get both a marriage license and...   \n",
       "\n",
       "                                      model_b_answer winner  \n",
       "0  As an AI, I don't have personal beliefs or opi...      A  \n",
       "1  A marriage license and a marriage certificate ...      B  \n",
       "2  In California, here are the general steps to o...      B  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn = pd.read_csv(\"lmsys-chatbot-arena/aux_files/dfn.csv\")\n",
    "unique_ids = dfn.id.unique()\n",
    "tagger = spacy.load(\"en_core_web_lg\")\n",
    "dfn.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c9d7fe-eb6d-4b6b-bd82-0c6ca1388665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(txt , limit , tokenizer , tagger , target_tags = [\"NOUN\" , \"VERB\", \"PROPN\"]):\n",
    "    reconstructed_str = \"\"\n",
    "    doc = tagger(txt)\n",
    "    txt_len = len(tokenizer(txt).encodings[0].tokens)\n",
    "\n",
    "    if txt_len > limit:\n",
    "        for token in doc:\n",
    "            if token.pos_ in target_tags:\n",
    "                if len(reconstructed_str) < 1:\n",
    "                    reconstructed_str = token.text\n",
    "                else:\n",
    "                    reconstructed_str += \" \" + token.text\n",
    "            if (token.pos_ == \"SYM\"):\n",
    "                if len(reconstructed_str) < 1:\n",
    "                    reconstructed_str = token.text\n",
    "                else:\n",
    "                    reconstructed_str += token.text\n",
    "        return reconstructed_str\n",
    "    else:\n",
    "        return reconstructed_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53aff84-c2a7-43d5-ad44-c03c6aee0d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 56759/56759 [00:06<00:00, 8864.94it/s]\n"
     ]
    }
   ],
   "source": [
    "id_list = []\n",
    "id_strings = []\n",
    "\n",
    "for _id in tqdm.tqdm(unique_ids):\n",
    "    id_df = dfn[dfn.id == _id]\n",
    "    id_list.append(_id)\n",
    "    id_str = \"\"\n",
    "    \n",
    "    for row in id_df.iterrows():\n",
    "        prompt = str(row[1]['prompt'])\n",
    "        \n",
    "        model_a_answer = str(row[1]['model_a_answer'])\n",
    "        model_b_answer = str(row[1]['model_b_answer'])\n",
    "        winner = row[1]['winner']\n",
    "\n",
    "        if winner == \"A\":\n",
    "            id_str += prompt + \"\\n\" + model_a_answer +'\\n'\n",
    "        if winner == \"B\":\n",
    "            id_str += prompt + \"\\n\" + model_b_answer +'\\n'\n",
    "            \n",
    "    id_strings.append(id_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4051014a-dcd3-4b0f-b23f-7844a2848670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 56759/56759 [00:24<00:00, 2274.43it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_id_strs = []\n",
    "for e in tqdm.tqdm(id_strings):\n",
    "    tokenized_id_strs.append(tokenizer([e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc327e5c-c279-4b66-b30b-29312cce9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 256\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f631d2-555e-4428-baca-2894127a0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_texts = []\n",
    "group_texts(tokenized_id_strs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c11123-97e4-4e8a-8be7-874c800f09a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
